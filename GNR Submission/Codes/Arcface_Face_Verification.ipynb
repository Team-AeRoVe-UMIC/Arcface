{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.python.keras.engine import training\n",
        "\n",
        "import hypar\n",
        "import network_16 as net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuxE9vJP90um"
      },
      "outputs": [],
      "source": [
        "# Model saved with Keras model.save()\n",
        "MODEL_PATH = 'models/arcface_weights.h5'\n",
        "cosine_threshold = 0.075\t#emperically set threshold\n",
        "\n",
        "def ResNet34():\n",
        "\n",
        "\timg_input = tf.keras.layers.Input(shape=(112, 112, 3))\n",
        "\n",
        "\tx = tf.keras.layers.ZeroPadding2D(padding=1, name='conv1_pad')(img_input)\n",
        "\tx = tf.keras.layers.Conv2D(64, 3, strides=1, use_bias=False, kernel_initializer='glorot_normal', name='conv1_conv')(x)\n",
        "\tx = tf.keras.layers.BatchNormalization(axis=3, epsilon=2e-5, momentum=0.9, name='conv1_bn')(x)\n",
        "\tx = tf.keras.layers.PReLU(shared_axes=[1, 2], name='conv1_prelu')(x)\n",
        "\tx = stack_fn(x)\n",
        "\n",
        "\tmodel = training.Model(img_input, x, name='ResNet34')\n",
        "\n",
        "\treturn model\n",
        "\n",
        "def block1(x, filters, kernel_size=3, stride=1, conv_shortcut=True, name=None):\n",
        "\tbn_axis = 3\n",
        "\n",
        "\tif conv_shortcut:\n",
        "\t\tshortcut = tf.keras.layers.Conv2D(filters, 1, strides=stride, use_bias=False, kernel_initializer='glorot_normal', name=name + '_0_conv')(x)\n",
        "\t\tshortcut = tf.keras.layers.BatchNormalization(axis=bn_axis, epsilon=2e-5, momentum=0.9, name=name + '_0_bn')(shortcut)\n",
        "\telse:\n",
        "\t\tshortcut = x\n",
        "\n",
        "\tx = tf.keras.layers.BatchNormalization(axis=bn_axis, epsilon=2e-5, momentum=0.9, name=name + '_1_bn')(x)\n",
        "\tx = tf.keras.layers.ZeroPadding2D(padding=1, name=name + '_1_pad')(x)\n",
        "\tx = tf.keras.layers.Conv2D(filters, 3, strides=1, kernel_initializer='glorot_normal', use_bias=False, name=name + '_1_conv')(x)\n",
        "\tx = tf.keras.layers.BatchNormalization(axis=bn_axis, epsilon=2e-5, momentum=0.9, name=name + '_2_bn')(x)\n",
        "\tx = tf.keras.layers.PReLU(shared_axes=[1, 2], name=name + '_1_prelu')(x)\n",
        "\n",
        "\tx = tf.keras.layers.ZeroPadding2D(padding=1, name=name + '_2_pad')(x)\n",
        "\tx = tf.keras.layers.Conv2D(filters, kernel_size, strides=stride, kernel_initializer='glorot_normal', use_bias=False, name=name + '_2_conv')(x)\n",
        "\tx = tf.keras.layers.BatchNormalization(axis=bn_axis, epsilon=2e-5, momentum=0.9, name=name + '_3_bn')(x)\n",
        "\n",
        "\tx = tf.keras.layers.Add(name=name + '_add')([shortcut, x])\n",
        "\treturn x\n",
        "\n",
        "def stack1(x, filters, blocks, stride1=2, name=None):\n",
        "\tx = block1(x, filters, stride=stride1, name=name + '_block1')\n",
        "\tfor i in range(2, blocks + 1):\n",
        "\t\tx = block1(x, filters, conv_shortcut=False, name=name + '_block' + str(i))\n",
        "\treturn x\n",
        "\n",
        "def stack_fn(x):\n",
        "\tx = stack1(x, 64, 3, name='conv2')\n",
        "\tx = stack1(x, 128, 4, name='conv3')\n",
        "\tx = stack1(x, 256, 6, name='conv4')\n",
        "\treturn stack1(x, 512, 3, name='conv5')\n",
        "\n",
        "def loadModel():\n",
        "\tbase_model = ResNet34()\n",
        "\tinputs = base_model.inputs[0]\n",
        "\tarcface_model = base_model.outputs[0]\n",
        "\tarcface_model = tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=2e-5)(arcface_model)\n",
        "\tarcface_model = tf.keras.layers.Dropout(0.4)(arcface_model)\n",
        "\tarcface_model = tf.keras.layers.Flatten()(arcface_model)\n",
        "\tarcface_model = tf.keras.layers.Dense(512, activation=None, use_bias=True, kernel_initializer=\"glorot_normal\")(arcface_model)\n",
        "\tembedding = tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=2e-5, name=\"embedding\", scale=True)(arcface_model)\n",
        "\tmodel = tf.keras.models.Model(inputs, embedding, name=base_model.name)\n",
        "\t\n",
        "\tmodel.load_weights(MODEL_PATH)\n",
        "\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load your trained model\n",
        "model = loadModel()\n",
        "print(\"ArcFace expects \",model.layers[0].input_shape[1:],\" inputs\")\n",
        "print(\"and it represents faces as \", model.layers[-1].output_shape[1:],\" dimensional vectors\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Siy-Ydb8-POL"
      },
      "outputs": [],
      "source": [
        "def get_distance(emb1,emb2):\n",
        "  \"\"\"\n",
        "  emb1 & emb2: are both 512 dimensional vectors from the trained resnet model\n",
        "\n",
        "  get_distance: returns cosine_distance\n",
        "  Check Out \"https://github.com/zestyoreo/Arcface/blob/main/get_distance()_test.ipynb\" for clarity\n",
        "  \"\"\"\n",
        "\n",
        "  a = np.matmul(np.transpose(emb1), emb2)\n",
        "  b = np.sum(np.multiply(emb1, emb1))\n",
        "  c = np.sum(np.multiply(emb2, emb2))\n",
        "  cosine_distance = 1 - (a / (np.sqrt(b) * np.sqrt(c)))\n",
        "\n",
        "  return cosine_distance\n",
        "\n",
        "\n",
        "def face_verify(img_path,img_path2,model):\n",
        "    \n",
        "    face1x = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
        "    if(face1x.shape[2]==4):\n",
        "      face1 = cv2.cvtColor(face1x, cv2.COLOR_BGRA2RGB)\n",
        "    else:\n",
        "      face1 = cv2.cvtColor(face1x, cv2.COLOR_BGR2RGB)\n",
        "    face2x = cv2.imread(img_path2, cv2.IMREAD_UNCHANGED)\n",
        "    if(face2x.shape[2]==4):\n",
        "      face2 = cv2.cvtColor(face2x, cv2.COLOR_BGRA2RGB)\n",
        "    else:\n",
        "      face2 = cv2.cvtColor(face2x, cv2.COLOR_BGR2RGB)\n",
        "    print('Original Dimensions : ',face1.shape)\n",
        "    plt.imshow(face1)\n",
        "    plt.show()\n",
        "    plt.imshow(face2)\n",
        "    plt.show()\n",
        "    # resize image\n",
        "    x1a = cv2.resize(face1, (112,112), interpolation = cv2.INTER_AREA)\n",
        "    print('Resized Dimensions : ',x1a.shape)\n",
        "    x1a = net.Resnet_preprocess(x1a)\n",
        "    img_pixels1 = np.expand_dims(x1a, axis = 0)\n",
        "    #img_pixels1 /= 255           #normalize input \n",
        "    print(img_pixels1.shape)\n",
        "    x2a = cv2.resize(face2, (112,112), interpolation = cv2.INTER_AREA)\n",
        "    x2a = net.Resnet_preprocess(x2a)\n",
        "    img_pixels2 = np.expand_dims(x2a, axis = 0)\n",
        "    #|img_pixels2 /= 255           #normalize input \n",
        "    # Be careful how your trained model deals with the input\n",
        "    # otherwise, it won't make correct prediction!\n",
        "    x1 = img_pixels1\n",
        "    x2 = img_pixels2\n",
        "\n",
        "    embedding1 = model.predict(x1)\n",
        "    embedding2 = model.predict(x2)\n",
        "    preds = \"Different People\"\n",
        "\n",
        "    cosine_distance = get_distance(embedding1.T,embedding2.T)\n",
        "    print(cosine_distance)\n",
        "    if cosine_distance<cosine_threshold:\n",
        "        preds = \"Same People\"\n",
        "\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_rIGH2O-aJ5"
      },
      "outputs": [],
      "source": [
        "# images are stored in the images folder. Change path here to do face verification with different images\n",
        "img_path1 = 'images/a.jpeg'\n",
        "img_path2 = 'images/b.jpeg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred = face_verify(img_path1,img_path2,model)\n",
        "print(pred)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Arcface GNR_Project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
